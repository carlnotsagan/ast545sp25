{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcF9ZWvjSybR"
   },
   "source": [
    "# In-Class Assignment 23\n",
    "\n",
    "**Due by the end of the day, Wednesday 9 April, 2025**\n",
    "\n",
    "## Exploring GPU Tools in Python - Numba and cuDF\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Develop an understanding of the vocabulary of heterogeneous computing.\n",
    "- Distinguish between CPU and GPU memory heirarchy and management.\n",
    "- Deploy and compare tools to GPU and evaluate possible speedups. \n",
    "\n",
    "\n",
    "Credit: [cuDF Github](https://github.com/rapidsai/cudf) & [GTC 2017 / \n",
    "Anaconda, Inc.](https://github.com/ContinuumIO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Minutes to RAPIDS cuDF's pandas accelerator mode (cudf.pandas)\n",
    "\n",
    "cuDF is a Python GPU DataFrame library (built on the Apache Arrow columnar memory format) for loading, joining, aggregating, filtering, and otherwise manipulating tabular data using a DataFrame style API in the style of pandas.\n",
    "\n",
    "cuDF now provides a pandas accelerator mode (`cudf.pandas`), allowing you to bring accelerated computing to your pandas workflows without requiring any code change.\n",
    "\n",
    "This notebook is a short introduction to `cudf.pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SH_h6ci1Sx0u"
   },
   "source": [
    "# ⚠️ Verify your setup\n",
    "\n",
    "First, we'll verify that you are running with an NVIDIA GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2vPCtXcCvUR",
    "outputId": "3918bbc5-1b9e-4b57-df41-e3577bd9f61a"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi  # this should display information about available GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KP0oc3PboQDv"
   },
   "source": [
    "With our GPU-enabled Colab runtime active, we're ready to go. cuDF is available by default in the GPU-enabled runtime.\n",
    "\n",
    "If you're interested in installing on other platforms, please visit https://rapids.ai/#quick-start to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhPt4Xj8THgo"
   },
   "outputs": [],
   "source": [
    "import cudf  # this should work without any errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iryQthjTMXQ"
   },
   "source": [
    "We'll also install `plotly-express` for visualizing data.\n",
    "\n",
    "### Environment Note\n",
    "If you're not running this notebook on Colab, you may need to reload the webpage for the `plotly.express` visualizations to work correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzBF7A8qTM27",
    "outputId": "625dcfed-93f4-408b-b5bc-9a196018d6e6"
   },
   "outputs": [],
   "source": [
    "!pip install plotly-express"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zGUeWvcTbDs"
   },
   "source": [
    "# Download the data\n",
    "\n",
    "The data we'll be working with is the [Parking Violations Issued - Fiscal Year 2022](https://data.cityofnewyork.us/City-Government/Parking-Violations-Issued-Fiscal-Year-2022/7mxj-7a6y) dataset from NYC Open Data.\n",
    "\n",
    "We're downloading a copy of this dataset from an s3 bucket hosted by NVIDIA to provide faster download speeds. We'll start by downloading the data. This should take about 30 seconds.\n",
    "\n",
    "## Data License and Terms\n",
    "As this dataset originates from the NYC Open Data Portal, it's governed by their license and terms of use.\n",
    "\n",
    "### Are there restrictions on how I can use Open Data?\n",
    "\n",
    "> Open Data belongs to all New Yorkers. There are no restrictions on the use of Open Data. Refer to Terms of Use for more information.\n",
    "\n",
    "### [Terms of Use](https://opendata.cityofnewyork.us/overview/#termsofuse)\n",
    "\n",
    "> By accessing datasets and feeds available through NYC Open Data, the user agrees to all of the Terms of Use of NYC.gov as well as the Privacy Policy for NYC.gov. The user also agrees to any additional terms of use defined by the agencies, bureaus, and offices providing data. Public data sets made available on NYC Open Data are provided for informational purposes. The City does not warranty the completeness, accuracy, content, or fitness for any particular purpose or use of any public data set made available on NYC Open Data, nor are any such warranties to be implied or inferred with respect to the public data sets furnished therein.\n",
    "\n",
    "> The City is not liable for any deficiencies in the completeness, accuracy, content, or fitness for any particular purpose or use of any public data set, or application utilizing such data set, provided by any third party.\n",
    "\n",
    "> Submitting City Agencies are the authoritative source of data available on NYC Open Data. These entities are responsible for data quality and retain version control of data sets and feeds accessed on the Site. Data may be updated, corrected, or refreshed at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EoQqNwsTqeP",
    "outputId": "c7538102-69e1-4f93-b50a-d121df47c07b"
   },
   "outputs": [],
   "source": [
    "!wget https://data.rapids.ai/datasets/nyc_parking/nyc_parking_violations_2022.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAvNFbYKWwti"
   },
   "source": [
    "# a. - Analysis using Standard Pandas (on Host/CPU only)\n",
    "\n",
    "First, let's use Pandas to read in some columns of the dataset:\n",
    "\n",
    "1. Load the following columns from the downloaded dataset using pandas: \n",
    "\n",
    "```\n",
    "\"Registration State\", \"Violation Description\", \"Vehicle Body Type\", \"Issue Date\", \"Summons Number\"\n",
    "```\n",
    "\n",
    "2. print the first 10 entries of this dataset using the `.sample` function in pandas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLRleX9xWxqX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "OLatEi7rW0la",
    "outputId": "242456f0-44b2-42a3-a1a7-efd5f298cdf9"
   },
   "outputs": [],
   "source": [
    "# read 5 columns data:\n",
    "df = pd.read_parquet(\n",
    "    \"nyc_parking_violations_2022.parquet\",\n",
    "    columns=[###\n",
    "\n",
    "\n",
    "# view a random sample of 10 rows:\n",
    "df.sample(###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7qXNJU9W53D"
   },
   "source": [
    "Next, we'll try to answer a few questions using the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmkFv9ZUW37g"
   },
   "source": [
    "## b. - Which parking violation is most commonly committed by vehicles from various U.S states?\n",
    "\n",
    "Each record in our dataset contains the state of registration of the offending vehicle, and the type of parking offence. Let's say we want to get the most common type of offence for vehicles registered in different states. We can do this in Pandas using a combination of [value_counts](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) and [GroupBy.head](https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.head.html):\n",
    "\n",
    "1. To answer this question, complete the groupby below. Pandas should output a condensed version of the output.\n",
    "\n",
    "> Of the data list, what is the highest violation type - its count, label, and state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "bHXq-s_ZXOQN",
    "outputId": "e8e86a64-d8ac-4d87-e1ac-b6aebec46bbd"
   },
   "outputs": [],
   "source": [
    "(df[[\"Registration State\", \"Violation Description\"]]  # get only these two columns\n",
    " .value_counts()  # get the count of offences per state and per type of offence\n",
    " .groupby(#### complete here ##### \n",
    " .head(1)  # get the first row in each group (the type of offence with the largest count)\n",
    " .sort_index()  # sort by state name\n",
    " .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lXF4v4SXRf3"
   },
   "source": [
    "The code above uses [method chaining](https://tomaugspurger.net/posts/method-chaining/) to combine a series of operations into a single statement. You might find it useful to break the code up into multiple statements and inspect each of the intermediate results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDeYr6xkXiDc"
   },
   "source": [
    "It looks like there are fewer violations on weekends, which makes sense! During the week, more people are driving in New York City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKBQcT64XlMr"
   },
   "source": [
    "## c. - Timing on CPU only\n",
    "\n",
    "Loading and processing this data took a little time. Let's measure how long these pipelines take in Pandas:\n",
    "\n",
    "1. Add the `%%time` magic command in python below to measure how long our data query takes using CPU only pandas. \n",
    "\n",
    "> What is the total walltime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "mDpQhus-Xnfs",
    "outputId": "8809b2ed-4528-436e-b1ed-6220e234abe7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"nyc_parking_violations_2022.parquet\",\n",
    "    columns=[\"Registration State\", \"Violation Description\", \"Vehicle Body Type\", \"Issue Date\", \"Summons Number\"]\n",
    ")\n",
    "\n",
    "(df[[\"Registration State\", \"Violation Description\"]]\n",
    " .value_counts()\n",
    " .groupby(\"Registration State\")\n",
    " .head(1)\n",
    " .sort_index()\n",
    " .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgAWS0yXXtGj"
   },
   "source": [
    "# d. - Using cudf.pandas\n",
    "\n",
    "Now, let's re-run the Pandas code above with the `cudf.pandas` extension loaded.\n",
    "\n",
    "Typically, you should load the `cudf.pandas` extension as the first step in your notebook, before importing any modules. Here, we explicitly restart the kernel to simulate that behavior.\n",
    "\n",
    "More info about `cudf.pandas` is available [here](https://docs.rapids.ai/api/cudf/stable/cudf_pandas/). \n",
    "\n",
    "1. Load `cudf.pandas` using the `load_ext` python magic command.\n",
    "\n",
    "2. Run our same data query and compare the total walltime to using CPU only pandas.\n",
    "\n",
    "> Is cuDF faster for this query? If so, by how much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hW5rUr2tXzUW",
    "outputId": "a980e847-8458-44b9-ef83-333fb38a982a"
   },
   "outputs": [],
   "source": [
    "get_ipython().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjvPsTlGZrW7"
   },
   "outputs": [],
   "source": [
    "## load `cudf.pandas` here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "XL_u4l5gZJte",
    "outputId": "6b681adf-08b4-4105-9a45-ddabbbc1ad34"
   },
   "outputs": [],
   "source": [
    "## time our same routine from above \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\n",
    "    \"nyc_parking_violations_2022.parquet\",\n",
    "    columns=[\"Registration State\", \"Violation Description\", \"Vehicle Body Type\", \"Issue Date\", \"Summons Number\"]\n",
    ")\n",
    "\n",
    "(df[[\"Registration State\", \"Violation Description\"]]\n",
    " .value_counts()\n",
    " .groupby(\"Registration State\")\n",
    " .head(1)\n",
    " .sort_index()\n",
    " .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMUrf6iMeBdM"
   },
   "source": [
    "Much faster! Operations that took 5-20 seconds can now potentially finish in just milliseconds without changing any code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00m6gUxqeGzk"
   },
   "source": [
    "# Understanding Performance\n",
    "\n",
    "`cudf.pandas` provides profiling utilities to help you better understand performance. With these tools, you can identify which parts of your code ran on the GPU and which parts ran on the CPU.\n",
    "\n",
    "They're accessible in the `cudf.pandas` namespace since the `cudf.pandas` extension was loaded above with `load_ext cudf.pandas`.\n",
    "\n",
    "#### Colab Note\n",
    "If you're running in Colab, the first time you run use the profiler it may take 10+ seconds due to Colab's debugger interacting with the built-in Python function [sys.settrace](https://docs.python.org/3/library/sys.html#sys.settrace) that we use for profiling. For demo purposes, this isn't an issue. Just run the cell again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yK3a-mIp0vr"
   },
   "source": [
    "# Using third-party libraries with cudf.pandas\n",
    "\n",
    "You can pass Pandas objects to third-party libraries when using `cudf.pandas`, just like you would when using regular Pandas.\n",
    "\n",
    "Below, we show an example of using [plotly-express](https://plotly.com/python/plotly-express/) to visualize the data we've been processing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0QwPQcAp2RV"
   },
   "source": [
    "## e. - Visualizing which states have more pickup trucks relative to other vehicles?\n",
    "\n",
    "1. For fun, run the cell below to answer this question. \n",
    "\n",
    "> Which state has more pickup trucks relative to other vehicles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "Ecs213eEqCd9",
    "outputId": "4db149b4-4342-4580-8357-5e4138d72524"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"Registration State\": \"reg_state\",\n",
    "    \"Vehicle Body Type\": \"vehicle_type\",\n",
    "})\n",
    "\n",
    "# vehicle counts per state:\n",
    "counts = df.groupby(\"reg_state\").size().sort_index()\n",
    "# vehicles with type \"PICK\" (Pickup Truck)\n",
    "pickup_counts = df.where(df[\"vehicle_type\"] == \"PICK\").groupby(\"reg_state\").size()\n",
    "# percentage of pickup trucks by state:\n",
    "pickup_frac = ((pickup_counts / counts) * 100).rename(\"% Pickup Trucks\")\n",
    "del pickup_frac[\"MB\"]  # (Manitoba is a huge outlier!)\n",
    "\n",
    "# plot the results:\n",
    "pickup_frac = pickup_frac.reset_index()\n",
    "px.choropleth(pickup_frac, locations=\"reg_state\", color=\"% Pickup Trucks\", locationmode=\"USA-states\", scope=\"usa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyVNtGUhtFs5"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "With `cudf.pandas`, you can keep using pandas as your primary dataframe library. When things start to get a little slow, just load the `cudf.pandas` and run your existing code on a GPU!\n",
    "\n",
    "To learn more, we encourage you to visit [rapids.ai/cudf-pandas](https://rapids.ai/cudf-pandas).\n",
    "\n",
    "\n",
    "1. Memory management is crucial when considering GPUs. If the time to copy the necessary data to device is substantial and the data parallelism is low, CPU will remain the better option. \n",
    "\n",
    "Check out some more ways to speed up Python code in examples from Dr. Chi-kwan Chan [:octocat:](https://github.com/rndsrc) and his recent Workshop [here](https://github.com/rndsrc/orbits-py)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
